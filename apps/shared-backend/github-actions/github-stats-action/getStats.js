#!/usr/bin/env node

import fetch from 'node-fetch'
import https from 'node:https'

// ‚Äî‚Äî Config from env / GitHub Action inputs ‚Äî‚Äî
const httpsAgent = new https.Agent({ keepAlive: true, maxSockets: 50, keepAliveMsecs: 10000 })
const ORG = process.env.ORG
const REPO = process.env.REPO
const GITHUB_TOKEN = process.env.GITHUB_TOKEN
// Hardcoded endpoints
const BASE_URL = 'https://gov.meshjs.dev/'
const NETLIFY_FUNCTION_URL = 'https://glittering-chebakia-09bd42.netlify.app/.netlify/functions/github-stats-background'

// Debug logging
console.log('üîç Environment variables:')
console.log(`  ORG: ${process.env.ORG}`)
console.log(`  REPO: ${process.env.REPO}`)
console.log(`  BASE_URL: ${BASE_URL}`)
console.log(`  NETLIFY_FUNCTION_URL: ${NETLIFY_FUNCTION_URL}`)
console.log(`  GITHUB_TOKEN: ${GITHUB_TOKEN ? '[REDACTED]' : '(not provided)'}`)

// Input validation function
function validateInputs() {
    const errors = []

    // Validate ORG
    if (!ORG) {
        errors.push('ORG is required but not provided')
    } else if (typeof ORG !== 'string' || ORG.trim() === '') {
        errors.push('ORG must be a non-empty string')
    } else if (!/^[a-zA-Z0-9_-]+$/.test(ORG.trim())) {
        errors.push('ORG must be a valid GitHub organization name (alphanumeric, hyphens, underscores only)')
    }

    // Validate REPO
    if (!REPO) {
        errors.push('REPO is required but not provided')
    } else if (typeof REPO !== 'string' || REPO.trim() === '') {
        errors.push('REPO must be a non-empty string')
    } else if (!/^[a-zA-Z0-9._-]+$/.test(REPO.trim())) {
        errors.push('REPO must be a valid GitHub repository name (alphanumeric, dots, hyphens, underscores only)')
    }

    // Validate GITHUB_TOKEN
    if (!GITHUB_TOKEN) {
        errors.push('GITHUB_TOKEN is required but not provided')
    } else if (typeof GITHUB_TOKEN !== 'string' || GITHUB_TOKEN.trim() === '') {
        errors.push('GITHUB_TOKEN must be a non-empty string')
    }

    // BASE_URL and NETLIFY_FUNCTION_URL are hardcoded

    return errors
}

// Parse and validate inputs
const validationErrors = validateInputs()

if (validationErrors.length > 0) {
    console.error('‚ùå Input validation failed:')
    validationErrors.forEach(error => console.error(`  - ${error}`))
    process.exit(1)
}

// Parse validated inputs
const parsedOrg = ORG.trim()
const parsedRepo = REPO.trim()
const parsedGithubToken = GITHUB_TOKEN.trim()
const parsedBaseUrl = BASE_URL.trim().replace(/\/$/, '')
const parsedFunctionUrl = NETLIFY_FUNCTION_URL.trim()

console.log('üìä Resolved values:')
console.log(`  ORG: ${parsedOrg}`)
console.log(`  REPO: ${parsedRepo}`)
console.log(`  BASE_URL: ${parsedBaseUrl}`)

// Helper function to make HTTP requests
async function makeRequest(url, options = {}) {
    try {
        // Add timeout to prevent hanging requests
        const controller = new AbortController()
        const timeoutId = setTimeout(() => controller.abort(), 30000) // 30 second timeout

        const response = await fetch(url, {
            headers: {
                'Content-Type': 'application/json',
                ...options.headers
            },
            agent: httpsAgent,
            signal: controller.signal,
            ...options
        })

        clearTimeout(timeoutId)

        if (!response.ok) {
            // read response body for better diagnostics
            let errorBodyText = ''
            try {
                errorBodyText = await response.text()
            } catch (_) {
                // ignore
            }
            let parsedBody
            try {
                parsedBody = errorBodyText ? JSON.parse(errorBodyText) : undefined
            } catch (_) {
                parsedBody = undefined
            }
            const details = parsedBody ? JSON.stringify(parsedBody) : (errorBodyText ? errorBodyText.substring(0, 1000) : '')
            const err = new Error(`HTTP ${response.status}: ${response.statusText}${details ? ` | Body: ${details}` : ''}`)
            // Attach status for retry logic
            // @ts-ignore
            err.status = response.status
            throw err
        }

        // Check if response has content
        const contentType = response.headers.get('content-type')
        const text = await response.text()

        if (!text || text.trim() === '') {
            console.log('‚ö†Ô∏è  Empty response received - data was processed successfully')
            return { success: true, message: 'Empty response - data processed successfully' }
        }

        // Try to parse as JSON, but handle non-JSON responses gracefully
        try {
            const parsed = JSON.parse(text)
            // Validate that we got a meaningful response
            if (parsed.success === false) {
                console.log(`‚ö†Ô∏è  Function returned error: ${parsed.message || 'Unknown error'}`)
                return parsed
            }
            return parsed
        } catch (parseError) {
            console.log(`‚ö†Ô∏è  Non-JSON response received: ${text.substring(0, 200)}...`)
            return { success: true, message: 'Non-JSON response', raw: text }
        }
    } catch (error) {
        if (error.name === 'AbortError') {
            console.error(`‚ùå Request timed out after 30 seconds`)
            throw new Error('Request timed out - the Netlify function may be unresponsive')
        }
        console.error(`‚ùå Request failed: ${error.message}`)
        throw error
    }
}

// Retry helper for GitHub API calls (handles transient network errors like "Premature close")
async function retryWithBackoff(fn, maxRetries = 8, initialDelayMs = 1000) {
    let attempt = 0
    let backoffMs = initialDelayMs
    const maxDelayMs = 30000
    // eslint-disable-next-line no-constant-condition
    while (true) {
        try {
            return await fn()
        } catch (error) {
            const status = error?.status || error?.response?.status
            const code = error?.code || error?.errno
            const message = typeof error?.message === 'string' ? error.message : ''

            const isStatusRetriable = status === 403 || status === 429 || (typeof status === 'number' && status >= 500)
            const isNetworkRetriable =
                message.includes('Premature close') ||
                message.includes('ERR_STREAM_PREMATURE_CLOSE') ||
                message.includes('socket hang up') ||
                message.includes('ECONNRESET') ||
                message.includes('ETIMEDOUT') ||
                message.includes('EAI_AGAIN') ||
                message.includes('network timeout') ||
                message.includes('NetworkError') ||
                message.includes('fetch failed') ||
                message.includes('Invalid response body')

            const shouldRetry = attempt < maxRetries && (isStatusRetriable || isNetworkRetriable)

            if (shouldRetry) {
                attempt += 1
                const jitter = Math.floor(Math.random() * 250)

                // Special handling for rate limits
                if (status === 429) {
                    console.warn(`‚è≥ Rate limit hit (attempt ${attempt}/${maxRetries}). Waiting 1 minute...`)
                    await delay(RATE_LIMIT_CONFIG.github.delayAfterRateLimit)
                } else {
                    console.warn(`Retrying after error ${status || code || message} (attempt ${attempt}/${maxRetries})...`)
                    await delay(backoffMs + jitter)
                }

                backoffMs = Math.min(backoffMs * 2, maxDelayMs)
                continue
            }
            throw error
        }
    }
}

function ghHeaders() {
    return {
        'Accept': 'application/vnd.github+json',
        'Authorization': `Bearer ${parsedGithubToken}`,
        'User-Agent': 'mesh-gov-stats-action/1.0 (+https://gov.meshjs.dev)',
        'X-GitHub-Api-Version': '2022-11-28'
    }
}

// Fetch org and repo metadata (including numeric IDs) for background function to ensure DB entries exist
async function fetchRepoMetadata() {
    const org = await retryWithBackoff(async () => {
        const resp = await fetch(`https://api.github.com/orgs/${parsedOrg}`, { headers: ghHeaders() })
        if (!resp.ok) throw { status: resp.status, message: await resp.text() }
        return resp.json()
    })

    const repo = await retryWithBackoff(async () => {
        const resp = await fetch(`https://api.github.com/repos/${parsedOrg}/${parsedRepo}`, { headers: ghHeaders() })
        if (!resp.ok) throw { status: resp.status, message: await resp.text() }
        return resp.json()
    })

    const orgInfo = {
        id: typeof org?.id === 'number' ? org.id : undefined,
        login: typeof org?.login === 'string' ? org.login : parsedOrg,
        name: typeof org?.name === 'string' ? org.name : undefined,
        description: typeof org?.description === 'string' ? org.description : undefined,
        avatar_url: typeof org?.avatar_url === 'string' ? org.avatar_url : undefined,
        html_url: typeof org?.html_url === 'string' ? org.html_url : undefined
    }
    const repoInfo = {
        id: typeof repo?.id === 'number' ? repo.id : undefined,
        name: typeof repo?.name === 'string' ? repo.name : parsedRepo,
        full_name: typeof repo?.full_name === 'string' ? repo.full_name : `${parsedOrg}/${parsedRepo}`,
        private: !!repo?.private,
        fork: !!repo?.fork,
        html_url: typeof repo?.html_url === 'string' ? repo.html_url : undefined,
        description: typeof repo?.description === 'string' ? repo.description : undefined
    }
    return { orgInfo, repoInfo }
}

async function fetchExistingIds() {
    const url = `${parsedBaseUrl}/api/github/existing-ids?org=${encodeURIComponent(parsedOrg)}&repo=${encodeURIComponent(parsedRepo)}`
    return await makeRequest(url, { method: 'GET' })
}

async function fetchAllMissingCommits(existingShasSet) {
    const results = []
    let page = 1
    while (true) {
        const data = await retryWithBackoff(async () => {
            const resp = await fetch(`https://api.github.com/repos/${parsedOrg}/${parsedRepo}/commits?per_page=50&page=${page}`, { headers: ghHeaders() })
            if (!resp.ok) throw { status: resp.status, message: await resp.text() }
            return resp.json()
        })
        if (!Array.isArray(data) || data.length === 0) break
        for (const item of data) {
            if (!existingShasSet.has(item.sha)) {
                // Ensure we have full commit details
                let details
                try {
                    details = await retryWithBackoff(async () => {
                        const resp = await fetch(`https://api.github.com/repos/${parsedOrg}/${parsedRepo}/commits/${item.sha}`, { headers: ghHeaders() })
                        if (!resp.ok) throw { status: resp.status, message: await resp.text() }
                        return resp.json()
                    })
                } catch (e) {
                    console.warn(`‚ö†Ô∏è  Skipping commit ${item.sha} after retries: ${e?.message || e}`)
                    // Skip this item and continue with the next
                    continue
                }
                // Minify commit payload to only what the Netlify function needs
                const filesCount = Array.isArray(details.files) ? details.files.length : 0
                const parents = Array.isArray(details.parents) ? details.parents.map((p) => ({ sha: p.sha })) : []
                results.push({
                    sha: details.sha,
                    author: details.author ? { login: details.author.login, avatar_url: details.author.avatar_url } : null,
                    committer: details.committer ? { login: details.committer.login, avatar_url: details.committer.avatar_url } : null,
                    commit: {
                        message: details.commit?.message ?? null,
                        author: { date: details.commit?.author?.date ?? null }
                    },
                    stats: details.stats
                        ? {
                            additions: details.stats.additions,
                            deletions: details.stats.deletions,
                            total: details.stats.total
                        }
                        : null,
                    // Only send a small array to preserve length semantics expected by the function
                    files: filesCount ? Array(filesCount).fill(0) : [],
                    parents
                })

                // Add delay between API calls to respect rate limits
                await delay(RATE_LIMIT_CONFIG.github.delayBetweenRequests)
            }
        }
        page += 1
    }
    return results
}

async function fetchAllMissingPulls(existingNumbersSet) {
    const results = []
    let page = 1
    while (true) {
        const data = await retryWithBackoff(async () => {
            const resp = await fetch(`https://api.github.com/repos/${parsedOrg}/${parsedRepo}/pulls?state=all&per_page=50&page=${page}`, { headers: ghHeaders() })
            if (!resp.ok) throw { status: resp.status, message: await resp.text() }
            return resp.json()
        })
        if (!Array.isArray(data) || data.length === 0) break
        for (const pr of data) {
            if (!existingNumbersSet.has(pr.number)) {
                let prDetails
                try {
                    prDetails = await retryWithBackoff(async () => {
                        const resp = await fetch(`https://api.github.com/repos/${parsedOrg}/${parsedRepo}/pulls/${pr.number}`, { headers: ghHeaders() })
                        if (!resp.ok) throw { status: resp.status, message: await resp.text() }
                        return resp.json()
                    })
                } catch (e) {
                    console.warn(`‚ö†Ô∏è  Skipping PR #${pr.number} details after retries: ${e?.message || e}`)
                    continue
                }
                let prCommits
                try {
                    prCommits = await retryWithBackoff(async () => {
                        const resp = await fetch(`https://api.github.com/repos/${parsedOrg}/${parsedRepo}/pulls/${pr.number}/commits`, { headers: ghHeaders() })
                        if (!resp.ok) throw { status: resp.status, message: await resp.text() }
                        return resp.json()
                    })
                } catch (e) {
                    console.warn(`‚ö†Ô∏è  Skipping PR #${pr.number} commits after retries: ${e?.message || e}`)
                    continue
                }
                // Minify PR payload to only fields used by the Netlify function
                const minDetails = {
                    number: prDetails.number,
                    title: prDetails.title,
                    body: prDetails.body ?? null,
                    state: prDetails.state,
                    created_at: prDetails.created_at,
                    updated_at: prDetails.updated_at,
                    closed_at: prDetails.closed_at,
                    merged_at: prDetails.merged_at,
                    additions: prDetails.additions ?? null,
                    deletions: prDetails.deletions ?? null,
                    changed_files: prDetails.changed_files ?? null,
                    commits: prDetails.commits ?? null,
                    user: prDetails.user ? { login: prDetails.user.login, avatar_url: prDetails.user.avatar_url } : null,
                    merged_by: prDetails.merged_by ? { login: prDetails.merged_by.login, avatar_url: prDetails.merged_by.avatar_url } : null,
                    requested_reviewers: Array.isArray(prDetails.requested_reviewers)
                        ? prDetails.requested_reviewers.map((r) => ({ login: r.login, avatar_url: r.avatar_url }))
                        : [],
                    assignees: Array.isArray(prDetails.assignees)
                        ? prDetails.assignees.map((a) => ({ login: a.login, avatar_url: a.avatar_url }))
                        : [],
                    labels: Array.isArray(prDetails.labels)
                        ? prDetails.labels.map((l) => ({ name: l.name }))
                        : []
                }
                const minCommits = Array.isArray(prCommits) ? prCommits.map((c) => ({ sha: c.sha })) : []
                results.push({ details: minDetails, commits: minCommits })

                // Add delay between API calls to respect rate limits
                await delay(RATE_LIMIT_CONFIG.github.delayBetweenRequests)
            }
        }
        page += 1
    }
    return results
}

async function fetchAllMissingIssues(existingNumbersSet) {
    const results = []
    let page = 1
    while (true) {
        const data = await retryWithBackoff(async () => {
            const resp = await fetch(`https://api.github.com/repos/${parsedOrg}/${parsedRepo}/issues?state=all&per_page=50&page=${page}`, { headers: ghHeaders() })
            if (!resp.ok) throw { status: resp.status, message: await resp.text() }
            return resp.json()
        })
        if (!Array.isArray(data) || data.length === 0) break
        for (const issue of data) {
            if (issue.pull_request) continue // skip PRs
            if (!existingNumbersSet.has(issue.number)) {
                // Minify issue payload to only fields used by the Netlify function
                results.push({
                    number: issue.number,
                    title: issue.title,
                    body: issue.body ?? null,
                    state: issue.state,
                    created_at: issue.created_at,
                    updated_at: issue.updated_at,
                    closed_at: issue.closed_at,
                    comments: issue.comments ?? null,
                    milestone: issue.milestone ? { title: issue.milestone.title } : null,
                    user: issue.user ? { login: issue.user.login, avatar_url: issue.user.avatar_url } : null,
                    assignees: Array.isArray(issue.assignees) ? issue.assignees.map((a) => ({ login: a.login, avatar_url: a.avatar_url })) : [],
                    labels: Array.isArray(issue.labels) ? issue.labels.map((l) => ({ name: l.name })) : []
                })
            }
        }
        page += 1
    }
    return results
}

// Rate limiting configuration
const RATE_LIMIT_CONFIG = {
    github: {
        delayBetweenRequests: 100, // 100ms between GitHub API calls
        delayAfterRateLimit: 60000, // 1 minute delay after hitting rate limit
        maxRetries: 3
    },
    netlify: {
        delayBetweenBatches: 500, // 500ms between Netlify function calls
        delayAfterError: 2000, // 2 second delay after errors
        maxRetries: 3
    }
}

// Helper function to add delays
const delay = (ms) => new Promise(resolve => setTimeout(resolve, ms))

// Check GitHub rate limit status
async function checkGitHubRateLimit() {
    try {
        const response = await fetch('https://api.github.com/rate_limit', { headers: ghHeaders() })
        if (!response.ok) {
            console.log('‚ö†Ô∏è  Could not check rate limit status')
            return null
        }
        const rateLimit = await response.json()
        const core = rateLimit.resources.core
        const remaining = core.remaining
        const resetTime = new Date(core.reset * 1000)

        console.log(`üìä GitHub Rate Limit: ${remaining}/${core.limit} remaining`)
        console.log(`üïê Rate limit resets at: ${resetTime.toISOString()}`)

        if (remaining < 100) {
            console.log('‚ö†Ô∏è  Rate limit is getting low, consider reducing batch sizes')
        }

        return { remaining, reset: core.reset, limit: core.limit }
    } catch (error) {
        console.log(`‚ö†Ô∏è  Rate limit check failed: ${error.message}`)
        return null
    }
}

// Main function
async function main() {
    console.log(`üöÄ Starting GitHub stats collection for repository: ${parsedOrg}/${parsedRepo}`)

    // Check GitHub rate limit status before starting
    console.log('üìä Checking GitHub rate limit status...')
    const rateLimitStatus = await checkGitHubRateLimit()
    if (rateLimitStatus && rateLimitStatus.remaining < 50) {
        console.log('‚ö†Ô∏è  Rate limit is very low. Consider running this action later.')
    }

    // Fetch org/repo info (with IDs) for background function to ensure DB entries exist
    console.log('üì• Fetching org/repo metadata...')
    const { orgInfo, repoInfo } = await fetchRepoMetadata()
    console.log(`üÜî GitHub org id: ${orgInfo?.id ?? 'unknown'}`)
    console.log(`üÜî GitHub repo id: ${repoInfo?.id ?? 'unknown'}`)

    // Trigger the Netlify background function
    console.log('üì• Fetching existing IDs from mesh-gov API...')
    const existing = await fetchExistingIds()
    const existingCommitShas = new Set(existing.commitShas || [])
    const existingPrNumbers = new Set(existing.prNumbers || [])
    const existingIssueNumbers = new Set(existing.issueNumbers || [])

    console.log(`üîé Found existing: commits=${existingCommitShas.size}, PRs=${existingPrNumbers.size}, issues=${existingIssueNumbers.size}`)

    console.log('‚¨áÔ∏è  Fetching missing commits from GitHub...')
    const missingCommits = await fetchAllMissingCommits(existingCommitShas)
    console.log(`üßÆ Missing commits: ${missingCommits.length}`)

    console.log('‚¨áÔ∏è  Fetching missing pull requests from GitHub...')
    const missingPulls = await fetchAllMissingPulls(existingPrNumbers)
    console.log(`üßÆ Missing PRs: ${missingPulls.length}`)

    console.log('‚¨áÔ∏è  Fetching missing issues from GitHub...')
    const missingIssues = await fetchAllMissingIssues(existingIssueNumbers)
    console.log(`üßÆ Missing issues: ${missingIssues.length}`)

    // Helper to chunk arrays
    const chunkArray = (arr, size) => {
        const chunks = []
        for (let i = 0; i < arr.length; i += size) chunks.push(arr.slice(i, i + size))
        return chunks
    }

    // Use conservative batch sizes to avoid gateway limits
    const COMMIT_BATCH_SIZE = 25
    const PULL_BATCH_SIZE = 5
    const ISSUE_BATCH_SIZE = 50

    let sentSomething = false

    if (missingCommits.length > 0) {
        console.log(`üì° Sending ${missingCommits.length} commits in batches of ${COMMIT_BATCH_SIZE}...`)
        const commitBatches = chunkArray(missingCommits, COMMIT_BATCH_SIZE)
        for (let i = 0; i < commitBatches.length; i++) {
            const batch = commitBatches[i]
            console.log(`  ‚û§ Commit batch ${i + 1}/${commitBatches.length} (size=${batch.length})`)
            const payload = {
                org: parsedOrg,
                repo: parsedRepo,
                orgInfo,
                repoInfo,
                commits: batch,
                pulls: [],
                issues: []
            }

            // Debug: Log payload details
            const payloadSize = JSON.stringify(payload).length
            console.log(`    üì¶ Payload size: ${payloadSize} bytes`)
            console.log(`    üìä Sample commit: ${JSON.stringify(batch[0]?.sha || 'none')}`)

            // Retry Netlify function calls with delays
            let response
            for (let retry = 0; retry < RATE_LIMIT_CONFIG.netlify.maxRetries; retry++) {
                try {
                    response = await makeRequest(parsedFunctionUrl, {
                        method: 'POST',
                        body: JSON.stringify(payload)
                    })
                    break // Success, exit retry loop
                } catch (error) {
                    if (retry < RATE_LIMIT_CONFIG.netlify.maxRetries - 1) {
                        console.log(`    ‚ö†Ô∏è  Netlify function call failed (attempt ${retry + 1}/${RATE_LIMIT_CONFIG.netlify.maxRetries}), retrying...`)
                        await delay(RATE_LIMIT_CONFIG.netlify.delayAfterError)
                        continue
                    }
                    throw error // Last retry failed
                }
            }

            console.log(`    ‚úÖ Response: ${JSON.stringify(response)}`)

            sentSomething = true

            // Add delay between batches to respect Netlify rate limits
            if (i < commitBatches.length - 1) {
                await delay(RATE_LIMIT_CONFIG.netlify.delayBetweenBatches)
            }
        }
    }

    if (missingPulls.length > 0) {
        console.log(`üì° Sending ${missingPulls.length} pull requests in batches of ${PULL_BATCH_SIZE}...`)
        const pullBatches = chunkArray(missingPulls, PULL_BATCH_SIZE)
        for (let i = 0; i < pullBatches.length; i++) {
            const batch = pullBatches[i]
            console.log(`  ‚û§ PR batch ${i + 1}/${pullBatches.length} (size=${batch.length})`)
            const payload = {
                org: parsedOrg,
                repo: parsedRepo,
                orgInfo,
                repoInfo,
                commits: [],
                pulls: batch,
                issues: []
            }

            // Debug: Log payload details
            const payloadSize = JSON.stringify(payload).length
            console.log(`    üì¶ Payload size: ${payloadSize} bytes`)
            console.log(`    üìä Sample PR: #${batch[0]?.details?.number || 'none'}`)

            // Retry Netlify function calls with delays
            let response
            for (let retry = 0; retry < RATE_LIMIT_CONFIG.netlify.maxRetries; retry++) {
                try {
                    response = await makeRequest(parsedFunctionUrl, {
                        method: 'POST',
                        body: JSON.stringify(payload)
                    })
                    break // Success, exit retry loop
                } catch (error) {
                    if (retry < RATE_LIMIT_CONFIG.netlify.maxRetries - 1) {
                        console.log(`    ‚ö†Ô∏è  Netlify function call failed (attempt ${retry + 1}/${RATE_LIMIT_CONFIG.netlify.maxRetries}), retrying...`)
                        await delay(RATE_LIMIT_CONFIG.netlify.delayAfterError)
                        continue
                    }
                    throw error // Last retry failed
                }
            }

            console.log(`    ‚úÖ Response: ${JSON.stringify(response)}`)
            sentSomething = true

            // Add delay between batches to respect Netlify rate limits
            if (i < pullBatches.length - 1) {
                await delay(RATE_LIMIT_CONFIG.netlify.delayBetweenBatches)
            }
        }
    }

    if (missingIssues.length > 0) {
        console.log(`üì° Sending ${missingIssues.length} issues in batches of ${ISSUE_BATCH_SIZE}...`)
        const issueBatches = chunkArray(missingIssues, ISSUE_BATCH_SIZE)
        for (let i = 0; i < issueBatches.length; i++) {
            const batch = issueBatches[i]
            console.log(`  ‚û§ Issue batch ${i + 1}/${issueBatches.length} (size=${batch.length})`)
            const payload = {
                org: parsedOrg,
                repo: parsedRepo,
                orgInfo,
                repoInfo,
                commits: [],
                pulls: [],
                issues: batch
            }

            // Debug: Log payload details
            const payloadSize = JSON.stringify(payload).length
            console.log(`    üìä Sample issue: #${batch[0]?.number || 'none'}`)

            // Retry Netlify function calls with delays
            let response
            for (let retry = 0; retry < RATE_LIMIT_CONFIG.netlify.maxRetries; retry++) {
                try {
                    response = await makeRequest(parsedFunctionUrl, {
                        method: 'POST',
                        body: JSON.stringify(payload)
                    })
                    break // Success, exit retry loop
                } catch (error) {
                    if (retry < RATE_LIMIT_CONFIG.netlify.maxRetries - 1) {
                        console.log(`    ‚ö†Ô∏è  Netlify function call failed (attempt ${retry + 1}/${RATE_LIMIT_CONFIG.netlify.maxRetries}), retrying...`)
                        await delay(RATE_LIMIT_CONFIG.netlify.delayAfterError)
                        continue
                    }
                    throw error // Last retry failed
                }
            }

            console.log(`    ‚úÖ Response: ${JSON.stringify(response)}`)
            sentSomething = true

            // Add delay between batches to respect Netlify rate limits
            if (i < issueBatches.length - 1) {
                await delay(RATE_LIMIT_CONFIG.netlify.delayBetweenBatches)
            }
        }
    }

    if (!sentSomething) {
        console.log('‚úÖ No new data to send')
    }

    console.log('üéâ Done')
    process.exit(0)
}

// Run the main function
main().catch(error => {
    console.error('‚ùå Fatal error:', error.message)
    process.exit(1)
})
